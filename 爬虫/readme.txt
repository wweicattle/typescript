利用ts进行爬虫进行总结
大致流程你要进行请求一个页面 ，之后进行捕获你需要的的信息。之后进行保存在json
1.你需要进行安装一些库，比如superagent进行请求页面，它是一个简单渐进式请求封装好node的请求。
2.之后你需要一个工具cheerio进行能够爬虫网页数据的工具，其语法类似jquery
3.在进行fs的数据进行存储等

说明:你必须要先将ts进行编译成js文件之后，之后在 执行js文件。这一系列的操作你需要进行简便转成一个操作
，这是你需要在进行安装concurrently ，它能够将script中的多个命令进行整合一起执行（不然你需要开启多个终端进行）
tsc-w  ：意思是将 ts代码进行编译，-w是只要代码有变化时，自动编译
nodemon ：是监听js文件的变化。有发生改变就进行执行一次  *js;（说明当你将爬虫中 的 数据进行存储在某文件中，这时nodemon会监听到，就会一直循环执行） 